{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import random_split\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    batch_size: int = 64\n",
    "    dataset_size: int = 2048\n",
    "    start_epoch: int = 0\n",
    "    n_epochs: int = 1000\n",
    "    lr: float = 0.0002\n",
    "    relu_slope: float = 0.2\n",
    "    dropout: float = 0.2\n",
    "    # randn dim\n",
    "    in_dim: int = 100\n",
    "    # 3 channels, 218x178\n",
    "    out_dim: int = 3 * 218 * 178\n",
    "    save_epoch_interval: int = 50\n",
    "    exp_id: str = 'mnist_gan_exp_1'\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logdir=runs/mnist_gan_exp_1\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "\n",
    "def setup_tensorboard(id):\n",
    "    # template = \"%Y-%m-%d_%H-%M-%S\"\n",
    "    print(f'logdir=runs/{id}')\n",
    "    writer = SummaryWriter(f'runs/{id}')\n",
    "    return writer\n",
    "\n",
    "writer = setup_tensorboard(config.exp_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cache():\n",
    "    # empty cache\n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "data=2048, batch_size=64, n_epochs=1000\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "\n",
    "# data = datasets.MNIST(root='./dataset', download=True, transform=transform)\n",
    "# <https://stackoverflow.com/questions/70896841/error-downloading-celeba-dataset-using-torchvision>\n",
    "data = datasets.CelebA(root='./dataset', download=True, transform=transform)\n",
    "\n",
    "# load dataset partially\n",
    "if config.dataset_size > 0:\n",
    "    data, _ = random_split(data, [config.dataset_size, len(data) - config.dataset_size])\n",
    "\n",
    "dataloader = DataLoader(data, batch_size=config.batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "print(f'data={len(dataloader) * config.batch_size}, batch_size={config.batch_size}, n_epochs={config.n_epochs}')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "clean_cache()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super(Generator, self).__init__()\n",
    "        sizes = [config.in_dim, 256, 512, 1024, config.out_dim]\n",
    "        self.slope = config.relu_slope\n",
    "        self.fc1 = nn.Linear(sizes[0], sizes[1])\n",
    "        self.fc2 = nn.Linear(sizes[1], sizes[2])\n",
    "        self.fc3 = nn.Linear(sizes[2], sizes[3])\n",
    "        self.fc4 = nn.Linear(sizes[3], sizes[4])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        slope = self.slope\n",
    "        x = F.leaky_relu(self.fc1(x), slope)\n",
    "        x = F.leaky_relu(self.fc2(x), slope)\n",
    "        x = F.leaky_relu(self.fc3(x), slope)\n",
    "        x = F.tanh(self.fc4(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super(Discriminator, self).__init__()\n",
    "        sizes = [config.out_dim, 1024, 512, 256, 1]\n",
    "        self.slope = config.relu_slope\n",
    "        self.dropout = config.dropout\n",
    "        self.fc1 = nn.Linear(sizes[0], sizes[1])\n",
    "        self.fc2 = nn.Linear(sizes[1], sizes[2])\n",
    "        self.fc3 = nn.Linear(sizes[2], sizes[3])\n",
    "        self.fc4 = nn.Linear(sizes[3], sizes[4])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        slope = self.slope\n",
    "        dropout = self.dropout\n",
    "        x = F.leaky_relu(self.fc1(x), slope)\n",
    "        x = F.dropout(x, dropout)\n",
    "        x = F.leaky_relu(self.fc2(x), slope)\n",
    "        x = F.dropout(x, dropout)\n",
    "        x = F.leaky_relu(self.fc3(x), slope)\n",
    "        x = F.dropout(x, dropout)\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_model(generator: Generator, discriminator: Discriminator, optim_generator, optim_discriminator, config: Config, epoch: int):\n",
    "    print(f'save models @ epoch={epoch}')\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'generator': generator.state_dict(),\n",
    "        'discriminator': discriminator.state_dict(),\n",
    "        'optim_generator': optim_generator.state_dict(),\n",
    "        'optim_discriminator': optim_discriminator.state_dict(),\n",
    "    }, f'models/{config.exp_id}_{epoch}.pt')\n",
    "\n",
    "def create_model(config: Config):\n",
    "    generator = Generator(config).to(device)\n",
    "    discriminator = Discriminator(config).to(device)\n",
    "\n",
    "    optim_generator = optim.AdamW(generator.parameters(), lr=config.lr)\n",
    "    optim_discriminator = optim.Adam(discriminator.parameters(), lr=config.lr)\n",
    "\n",
    "    return generator, discriminator, optim_generator, optim_discriminator\n",
    "\n",
    "\n",
    "def load_model(config: Config, start_epoch: int):\n",
    "    checkpoint = torch.load(f'models/{config.exp_id}_{start_epoch}.pt')\n",
    "\n",
    "    config.start_epoch = checkpoint['epoch'] + 1\n",
    "    generator = Generator(config).to(device)\n",
    "    generator.load_state_dict(checkpoint['generator'])\n",
    "    generator.train()\n",
    "    discriminator = Discriminator(config).to(device)\n",
    "    discriminator.load_state_dict(checkpoint['discriminator'])\n",
    "    discriminator.train()\n",
    "\n",
    "    optim_generator = optim.AdamW(generator.parameters(), lr=config.lr)\n",
    "    optim_generator.load_state_dict(checkpoint['optim_generator'])\n",
    "    optim_discriminator = optim.Adam(discriminator.parameters(), lr=config.lr)\n",
    "    optim_discriminator.load_state_dict(checkpoint['optim_discriminator'])\n",
    "    \n",
    "    return generator, discriminator, optim_generator, optim_discriminator\n",
    "\n",
    "def train_discriminator(\n",
    "    generator: Generator, \n",
    "    discriminator: Discriminator, \n",
    "    optim_discriminator, \n",
    "    x: torch.Tensor,\n",
    "    criterion,\n",
    "    config: Config,\n",
    "    step: int,\n",
    "):\n",
    "    discriminator.zero_grad()\n",
    "\n",
    "    x_real, y_real = x.view(-1, config.out_dim).to(device), torch.ones(config.batch_size, 1).to(device)\n",
    "    x_real, y_real = Variable(x_real), Variable(y_real)\n",
    "    \n",
    "    d_output = discriminator(x_real)\n",
    "    # print(f'd_output: {d_output.shape}, y_real: {y_real.shape}')\n",
    "    loss_real = criterion(d_output, y_real)\n",
    "\n",
    "    # train discriminator with fake data\n",
    "    z = Variable(torch.randn(config.batch_size, config.in_dim, device = device))\n",
    "    x_fake, y_fake = generator(z), torch.zeros(config.batch_size, 1).to(device)\n",
    "    \n",
    "    d_output = discriminator(x_fake)\n",
    "    loss_fake = criterion(d_output, y_fake)\n",
    "\n",
    "    loss = loss_real + loss_fake\n",
    "    loss.backward()\n",
    "    optim_discriminator.step()\n",
    "    l = loss.item()\n",
    "    del loss\n",
    "    writer.add_scalar('loss/discriminator', l, step)\n",
    "    \n",
    "def train_generator(\n",
    "    generator: Generator,\n",
    "    discriminator: Discriminator,\n",
    "    optim_generator,\n",
    "    criterion,\n",
    "    config: Config,\n",
    "    step: int,\n",
    "):\n",
    "    generator.zero_grad()\n",
    "    batch_size = config.batch_size\n",
    "    in_dim = config.in_dim\n",
    "    z = Variable(torch.randn(batch_size, in_dim, device = device))\n",
    "    y = Variable(torch.ones(batch_size, 1).to(device))\n",
    "\n",
    "    g_output = generator(z)\n",
    "    d_output = discriminator(g_output)\n",
    "    loss_generator = criterion(d_output, y)\n",
    "\n",
    "    loss_generator.backward()\n",
    "    optim_generator.step()\n",
    "    loss = loss_generator.item()\n",
    "    writer.add_scalar('loss/generator', loss, step)\n",
    "    del loss_generator\n",
    "\n",
    "\n",
    "def train(\n",
    "    writer: SummaryWriter,\n",
    "    generator: Generator, \n",
    "    discriminator: Discriminator,\n",
    "    optim_generator,\n",
    "    optim_discriminator,\n",
    "    dataloader: DataLoader,\n",
    "    config: Config,\n",
    "):\n",
    "    criterion = nn.BCELoss()\n",
    "    for epoch in range(config.start_epoch, config.start_epoch + config.n_epochs):\n",
    "        now = datetime.datetime.now\n",
    "        print(f'[{now()}] Epoch {epoch}')\n",
    "        for i, (x, _) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            # print(f'[{now()}] Epoch {epoch} batch {i}')\n",
    "            step = epoch * len(dataloader) + i\n",
    "            train_discriminator(generator, discriminator, optim_discriminator, x, criterion, config, step)\n",
    "            train_generator(generator, discriminator, optim_generator, criterion, config, step)\n",
    "\n",
    "        # generate image\n",
    "        with torch.no_grad():\n",
    "            # input\n",
    "            z = torch.randn(config.batch_size, config.in_dim).to(device)\n",
    "            images = generator(z).view(-1, *shape)\n",
    "            writer.add_images(f'generated_image', images, epoch)\n",
    "\n",
    "        if epoch % config.save_epoch_interval == 0:\n",
    "            save_model(generator, discriminator, optim_generator, optim_discriminator, config, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-06-16 02:52:29.556031] Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python39\\site-packages\\torch\\nn\\functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "D:\\python39\\site-packages\\torch\\nn\\functional.py:1933: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save models @ epoch=3\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 1440127744 vs 1440127632",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mD:\\python39\\site-packages\\torch\\serialization.py:380\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m--> 380\u001b[0m     _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[0;32m    381\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mD:\\python39\\site-packages\\torch\\serialization.py:604\u001b[0m, in \u001b[0;36m_save\u001b[1;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[0;32m    603\u001b[0m num_bytes \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39mnbytes()\n\u001b[1;32m--> 604\u001b[0m zip_file\u001b[39m.\u001b[39;49mwrite_record(name, storage\u001b[39m.\u001b[39;49mdata_ptr(), num_bytes)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\dev\\ml\\994G601-gan-morphing\\gan.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000011?line=4'>5</a>\u001b[0m generator, discriminator, optim_generator, optim_discriminator \u001b[39m=\u001b[39m load_model(config, \u001b[39m2\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000011?line=5'>6</a>\u001b[0m \u001b[39m# generator, discriminator, optim_generator, optim_discriminator = create_model(config)\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000011?line=6'>7</a>\u001b[0m train(writer, generator, discriminator, optim_generator, optim_discriminator, dataloader, config)\n",
      "\u001b[1;32md:\\dev\\ml\\994G601-gan-morphing\\gan.ipynb Cell 11'\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(writer, generator, discriminator, optim_generator, optim_discriminator, dataloader, config)\u001b[0m\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=120'>121</a>\u001b[0m     writer\u001b[39m.\u001b[39madd_images(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mgenerated_image\u001b[39m\u001b[39m'\u001b[39m, images, epoch)\n\u001b[0;32m    <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=122'>123</a>\u001b[0m \u001b[39mif\u001b[39;00m epoch \u001b[39m%\u001b[39m config\u001b[39m.\u001b[39msave_epoch_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=123'>124</a>\u001b[0m     save_model(generator, discriminator, optim_generator, optim_discriminator, config, epoch)\n",
      "\u001b[1;32md:\\dev\\ml\\994G601-gan-morphing\\gan.ipynb Cell 11'\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(generator, discriminator, optim_generator, optim_discriminator, config, epoch)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_model\u001b[39m(generator: Generator, discriminator: Discriminator, optim_generator, optim_discriminator, config: Config, epoch: \u001b[39mint\u001b[39m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=1'>2</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39msave models @ epoch=\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=2'>3</a>\u001b[0m     torch\u001b[39m.\u001b[39;49msave({\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=3'>4</a>\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m'\u001b[39;49m: epoch,\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=4'>5</a>\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mgenerator\u001b[39;49m\u001b[39m'\u001b[39;49m: generator\u001b[39m.\u001b[39;49mstate_dict(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=5'>6</a>\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39mdiscriminator\u001b[39;49m\u001b[39m'\u001b[39;49m: discriminator\u001b[39m.\u001b[39;49mstate_dict(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=6'>7</a>\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39moptim_generator\u001b[39;49m\u001b[39m'\u001b[39;49m: optim_generator\u001b[39m.\u001b[39;49mstate_dict(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=7'>8</a>\u001b[0m         \u001b[39m'\u001b[39;49m\u001b[39moptim_discriminator\u001b[39;49m\u001b[39m'\u001b[39;49m: optim_discriminator\u001b[39m.\u001b[39;49mstate_dict(),\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/dev/ml/994G601-gan-morphing/gan.ipynb#ch0000010?line=8'>9</a>\u001b[0m     }, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mmodels/\u001b[39;49m\u001b[39m{\u001b[39;49;00mconfig\u001b[39m.\u001b[39;49mexp_id\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mepoch\u001b[39m}\u001b[39;49;00m\u001b[39m.pt\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[1;32mD:\\python39\\site-packages\\torch\\serialization.py:381\u001b[0m, in \u001b[0;36msave\u001b[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[0;32m    379\u001b[0m     \u001b[39mwith\u001b[39;00m _open_zipfile_writer(opened_file) \u001b[39mas\u001b[39;00m opened_zipfile:\n\u001b[0;32m    380\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m--> 381\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    382\u001b[0m _legacy_save(obj, opened_file, pickle_module, pickle_protocol)\n",
      "File \u001b[1;32mD:\\python39\\site-packages\\torch\\serialization.py:260\u001b[0m, in \u001b[0;36m_open_zipfile_writer_buffer.__exit__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mwrite_end_of_file()\n\u001b[0;32m    261\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuffer\u001b[39m.\u001b[39mflush()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\caffe2\\serialize\\inline_container.cc:300] . unexpected pos 1440127744 vs 1440127632"
     ]
    }
   ],
   "source": [
    "clean_cache()\n",
    "\n",
    "# (channel, width, height)\n",
    "shape = iter(dataloader).next()[0].shape[1:]\n",
    "generator, discriminator, optim_generator, optim_discriminator = load_model(config, 2)\n",
    "# generator, discriminator, optim_generator, optim_discriminator = create_model(config)\n",
    "train(writer, generator, discriminator, optim_generator, optim_discriminator, dataloader, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator(\n",
      "  (fc1): Linear(in_features=100, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=1024, bias=True)\n",
      "  (fc4): Linear(in_features=1024, out_features=116412, bias=True)\n",
      ")\n",
      "Discriminator(\n",
      "  (fc1): Linear(in_features=116412, out_features=1024, bias=True)\n",
      "  (fc2): Linear(in_features=1024, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc4): Linear(in_features=256, out_features=1, bias=True)\n",
      ")\n",
      "tensor([[[[-1.1310e-02,  2.4825e-02, -3.0744e-02,  ...,  3.0162e-02,\n",
      "           -8.7601e-03,  4.7575e-02],\n",
      "          [-7.2179e-02,  4.0158e-02,  1.0752e-02,  ...,  1.9712e-02,\n",
      "           -2.4964e-02,  5.5346e-02],\n",
      "          [ 4.9146e-02, -1.0183e-01, -3.4617e-02,  ...,  1.3988e-02,\n",
      "            8.6680e-03,  1.9955e-02],\n",
      "          ...,\n",
      "          [-3.6754e-02, -1.9263e-02, -3.5289e-02,  ..., -1.1569e-02,\n",
      "            3.4800e-02, -6.9653e-02],\n",
      "          [-3.3608e-02, -4.6223e-02, -5.9052e-02,  ..., -1.0291e-02,\n",
      "           -4.7401e-02,  4.8903e-02],\n",
      "          [-1.1579e-02, -8.2470e-02, -5.3737e-02,  ..., -1.4030e-02,\n",
      "            1.9379e-02,  3.1097e-02]],\n",
      "\n",
      "         [[-2.1467e-02, -5.0917e-02, -5.5068e-03,  ...,  4.6226e-02,\n",
      "            3.8791e-02, -9.1916e-02],\n",
      "          [-4.5924e-03, -3.0593e-03,  2.5678e-02,  ..., -5.5158e-02,\n",
      "            4.9873e-02, -1.0660e-02],\n",
      "          [ 3.7130e-02,  4.5199e-03,  4.2043e-02,  ..., -5.9121e-02,\n",
      "            1.0834e-02,  4.2202e-02],\n",
      "          ...,\n",
      "          [-1.9941e-02,  3.2476e-02,  1.9076e-02,  ..., -3.4572e-02,\n",
      "           -2.8104e-02, -3.4442e-02],\n",
      "          [ 3.8161e-02, -5.5215e-02,  6.8081e-02,  ...,  1.5889e-02,\n",
      "           -2.7808e-02, -8.2448e-02],\n",
      "          [ 5.0487e-02, -3.7693e-02, -7.0920e-02,  ...,  4.4462e-02,\n",
      "            6.5489e-02, -3.5600e-02]],\n",
      "\n",
      "         [[-4.6572e-03, -8.5645e-02, -2.2622e-02,  ...,  8.3550e-03,\n",
      "           -5.9094e-02, -4.6344e-02],\n",
      "          [ 3.9740e-02, -5.7050e-02,  3.1035e-02,  ..., -4.7055e-02,\n",
      "            1.0451e-01, -2.1328e-02],\n",
      "          [-1.0844e-03,  4.8586e-02, -8.7059e-03,  ...,  3.1271e-02,\n",
      "           -5.1908e-02, -1.4226e-02],\n",
      "          ...,\n",
      "          [ 1.1720e-02, -1.2267e-01, -1.4971e-02,  ..., -2.0649e-02,\n",
      "            2.1536e-02, -2.5010e-02],\n",
      "          [-1.8546e-02,  5.3121e-02, -6.0912e-02,  ...,  1.9356e-02,\n",
      "           -7.7894e-03, -6.3369e-03],\n",
      "          [ 2.5605e-02, -4.4618e-02,  4.4553e-02,  ...,  3.0262e-02,\n",
      "           -1.6497e-02, -1.0024e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.3327e-02, -5.5889e-02, -2.6777e-03,  ...,  4.3305e-02,\n",
      "            2.1848e-03, -7.4436e-02],\n",
      "          [-8.5101e-02,  7.1227e-02, -1.4263e-03,  ..., -1.1852e-02,\n",
      "           -3.4364e-02, -6.9475e-03],\n",
      "          [ 1.6513e-02, -3.0295e-02,  5.3316e-02,  ...,  1.6555e-02,\n",
      "            1.5745e-02,  2.4314e-02],\n",
      "          ...,\n",
      "          [-2.8021e-02, -6.8412e-02,  1.7014e-02,  ..., -2.1706e-02,\n",
      "            2.3826e-02, -1.1593e-02],\n",
      "          [-1.7638e-02, -3.0683e-02, -3.3928e-02,  ...,  5.1877e-02,\n",
      "            3.1924e-03,  1.6205e-02],\n",
      "          [ 6.3663e-02, -1.5638e-04, -7.4774e-02,  ...,  7.2093e-02,\n",
      "           -3.9652e-02,  1.2074e-02]],\n",
      "\n",
      "         [[-9.0594e-02,  3.8921e-03, -7.1309e-02,  ...,  6.9940e-02,\n",
      "           -1.0949e-02, -5.5129e-02],\n",
      "          [-5.1909e-03,  2.7920e-02,  1.0020e-01,  ..., -3.5727e-02,\n",
      "            5.5653e-02, -2.1396e-02],\n",
      "          [ 5.7253e-02,  5.9813e-02,  4.0752e-02,  ..., -6.4700e-02,\n",
      "           -7.2899e-02,  6.7367e-02],\n",
      "          ...,\n",
      "          [ 1.8100e-02,  7.8870e-03,  1.0645e-02,  ..., -2.7296e-02,\n",
      "            2.0489e-02, -3.8959e-02],\n",
      "          [-5.7059e-02, -6.3085e-02,  7.7433e-02,  ...,  7.9096e-03,\n",
      "           -1.3617e-02, -4.3252e-02],\n",
      "          [ 2.5444e-02, -7.2766e-02, -2.4026e-02,  ...,  4.9151e-02,\n",
      "            1.1834e-01,  5.0249e-03]],\n",
      "\n",
      "         [[-2.4719e-02, -5.7117e-02, -4.6824e-02,  ...,  2.1722e-03,\n",
      "           -2.8604e-02,  3.3496e-02],\n",
      "          [ 3.9968e-02, -1.0307e-01,  2.0537e-02,  ..., -1.1505e-01,\n",
      "            9.5025e-02, -4.3157e-02],\n",
      "          [ 2.4888e-02, -1.5113e-02,  2.5025e-02,  ..., -1.5679e-02,\n",
      "           -2.8012e-02,  5.3642e-03],\n",
      "          ...,\n",
      "          [-7.2374e-02, -1.0353e-02, -3.9929e-02,  ..., -3.6677e-02,\n",
      "            8.1144e-02, -3.2173e-02],\n",
      "          [-2.2533e-02,  1.3592e-02, -7.5155e-04,  ...,  3.2542e-03,\n",
      "            8.4062e-02,  6.6416e-02],\n",
      "          [ 4.9276e-02,  4.8746e-02,  6.0165e-02,  ...,  6.7770e-03,\n",
      "           -1.7034e-02, -1.1506e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.7180e-02, -1.4051e-02,  4.8555e-02,  ...,  4.5752e-02,\n",
      "           -4.1915e-02,  8.1465e-02],\n",
      "          [ 1.5023e-02,  4.8844e-02,  2.8746e-02,  ...,  3.9993e-02,\n",
      "            4.8883e-03,  5.2895e-02],\n",
      "          [ 5.9282e-02, -6.6345e-02,  3.9769e-02,  ..., -1.2339e-02,\n",
      "            1.9197e-02,  4.5788e-02],\n",
      "          ...,\n",
      "          [-7.9590e-03, -9.4655e-02,  5.2274e-02,  ...,  3.5384e-02,\n",
      "           -3.4010e-02, -3.9992e-02],\n",
      "          [-5.0691e-02, -1.5180e-01, -6.1937e-02,  ...,  2.2111e-02,\n",
      "            1.0825e-02,  6.6618e-03],\n",
      "          [-4.9110e-02,  4.3185e-02, -2.1106e-02,  ..., -3.6395e-02,\n",
      "           -3.4312e-02,  8.3390e-02]],\n",
      "\n",
      "         [[ 4.2739e-02,  1.9948e-02, -1.6793e-02,  ...,  3.6444e-02,\n",
      "            1.7866e-02, -1.3164e-01],\n",
      "          [ 5.0114e-02, -9.9913e-03, -1.0804e-02,  ...,  7.2944e-03,\n",
      "            9.0081e-02,  5.9579e-02],\n",
      "          [ 6.6475e-02,  2.0952e-02,  7.7204e-02,  ..., -9.6888e-02,\n",
      "            7.0025e-03,  5.9448e-02],\n",
      "          ...,\n",
      "          [-1.2330e-02, -1.7463e-03,  1.3384e-02,  ...,  3.4053e-04,\n",
      "            2.7037e-02, -3.0831e-02],\n",
      "          [-7.1294e-02, -5.6063e-02, -4.9500e-03,  ...,  1.2803e-02,\n",
      "           -4.8136e-02, -3.5635e-02],\n",
      "          [ 2.5270e-02, -3.8635e-02, -1.7813e-02,  ...,  7.0128e-02,\n",
      "            1.0885e-01, -4.7221e-02]],\n",
      "\n",
      "         [[-2.3107e-02, -4.6250e-02, -1.4492e-03,  ...,  8.0699e-02,\n",
      "           -2.3672e-02, -1.7963e-02],\n",
      "          [ 7.2203e-02,  3.7575e-02,  1.1569e-02,  ..., -1.1874e-02,\n",
      "            3.6582e-02, -9.4598e-02],\n",
      "          [-3.7874e-02, -1.3262e-02,  3.1445e-03,  ...,  2.6784e-03,\n",
      "           -6.7450e-02, -8.5352e-02],\n",
      "          ...,\n",
      "          [-3.4501e-02, -1.4378e-01, -1.4304e-02,  ..., -1.5496e-02,\n",
      "           -3.1074e-03, -6.8416e-02],\n",
      "          [-2.4746e-02,  3.2315e-02, -8.2111e-02,  ...,  6.5747e-03,\n",
      "           -9.0589e-03,  7.9632e-03],\n",
      "          [ 1.3281e-03,  4.6111e-02,  3.7829e-02,  ...,  4.1457e-02,\n",
      "           -6.3841e-02, -4.0554e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.0263e-02, -7.5857e-02, -1.2818e-02,  ..., -1.1514e-02,\n",
      "           -2.0077e-02,  5.8020e-03],\n",
      "          [-9.2879e-02,  1.0942e-01,  3.6628e-02,  ..., -3.1580e-02,\n",
      "            2.0412e-02,  1.5909e-02],\n",
      "          [ 5.5067e-03, -5.3236e-02,  5.5513e-03,  ...,  4.1014e-02,\n",
      "           -5.1335e-02, -5.1946e-02],\n",
      "          ...,\n",
      "          [-5.6079e-02, -6.7547e-02, -6.3853e-02,  ...,  9.6346e-02,\n",
      "           -5.7789e-02,  5.6349e-02],\n",
      "          [-4.0181e-03, -5.7192e-02,  2.9598e-02,  ...,  5.8470e-02,\n",
      "            5.1662e-02,  4.5403e-02],\n",
      "          [-6.1301e-02, -1.6936e-02, -3.4235e-03,  ..., -6.4486e-04,\n",
      "           -5.0679e-02,  4.5025e-02]],\n",
      "\n",
      "         [[ 7.9103e-03,  5.7779e-02,  1.9961e-02,  ...,  1.6293e-02,\n",
      "            3.1469e-03, -4.6539e-02],\n",
      "          [ 2.8657e-02,  2.8362e-02,  5.2466e-02,  ..., -1.7573e-02,\n",
      "            6.7191e-03,  8.7363e-02],\n",
      "          [ 3.2904e-02, -4.8605e-02,  4.8811e-02,  ...,  1.7109e-02,\n",
      "            1.6835e-02,  1.0565e-02],\n",
      "          ...,\n",
      "          [ 8.7377e-03, -1.0029e-01,  6.0115e-03,  ..., -2.1126e-02,\n",
      "           -3.8463e-03,  3.6924e-02],\n",
      "          [-6.3393e-02, -3.5941e-02,  3.4691e-02,  ...,  6.0910e-02,\n",
      "            2.0487e-02,  1.0518e-02],\n",
      "          [-7.5250e-03, -3.9096e-02, -6.6349e-02,  ...,  3.0374e-02,\n",
      "           -8.1913e-03, -1.0625e-02]],\n",
      "\n",
      "         [[-1.9670e-02, -1.4105e-02, -6.1230e-02,  ...,  8.9099e-02,\n",
      "           -8.1356e-02,  9.6169e-03],\n",
      "          [ 1.0203e-01, -5.7081e-02,  4.6575e-02,  ..., -7.8278e-03,\n",
      "            4.6351e-02, -7.4113e-02],\n",
      "          [ 2.7775e-02,  1.5254e-02,  2.9776e-03,  ..., -5.8084e-03,\n",
      "           -6.3610e-02, -3.9935e-02],\n",
      "          ...,\n",
      "          [-4.2615e-02, -7.2466e-02, -3.8950e-02,  ...,  6.5310e-03,\n",
      "            9.3562e-02, -8.2448e-02],\n",
      "          [-1.3539e-02, -7.1560e-02, -2.7565e-02,  ..., -4.0141e-03,\n",
      "            5.5845e-02,  9.3639e-02],\n",
      "          [-3.7065e-02, -4.6623e-02, -7.3565e-03,  ...,  1.9940e-02,\n",
      "           -8.3298e-02, -2.6497e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7249e-02, -7.8116e-02,  1.2322e-02,  ...,  7.5226e-02,\n",
      "            7.1476e-02,  5.9764e-02],\n",
      "          [-3.3464e-02,  4.6767e-02,  6.3903e-02,  ..., -1.2899e-02,\n",
      "           -2.3242e-02,  4.7075e-02],\n",
      "          [ 3.7821e-03,  2.6447e-02,  4.1041e-02,  ..., -6.6274e-02,\n",
      "           -1.0276e-02,  1.0609e-02],\n",
      "          ...,\n",
      "          [ 5.5911e-02,  1.7679e-02, -4.8938e-02,  ..., -2.6881e-02,\n",
      "            5.3001e-02, -6.0660e-02],\n",
      "          [-1.9138e-02, -1.0398e-01, -5.0367e-02,  ..., -3.6910e-03,\n",
      "           -2.9939e-02,  8.9581e-02],\n",
      "          [-9.0539e-02,  8.5617e-03, -5.4169e-03,  ..., -2.9336e-02,\n",
      "           -1.9146e-02,  6.8793e-02]],\n",
      "\n",
      "         [[ 9.9324e-03,  3.8985e-02, -1.4516e-02,  ...,  2.5866e-03,\n",
      "           -7.1876e-03, -1.4196e-01],\n",
      "          [-3.5677e-02, -1.3343e-02, -4.2622e-03,  ...,  4.2314e-02,\n",
      "            1.4547e-01,  1.0196e-01],\n",
      "          [ 3.3547e-02, -3.1888e-02,  2.6638e-02,  ..., -3.1776e-02,\n",
      "            3.7639e-02,  3.6199e-02],\n",
      "          ...,\n",
      "          [-9.6289e-03, -3.6486e-02, -4.0151e-02,  ..., -9.5110e-02,\n",
      "           -9.5447e-02,  1.9291e-02],\n",
      "          [ 1.5183e-02,  2.4672e-02,  2.6376e-02,  ..., -2.5446e-02,\n",
      "           -1.0716e-02, -8.5805e-02],\n",
      "          [ 1.0035e-01,  1.6030e-02,  2.6455e-02,  ...,  5.8431e-02,\n",
      "            5.1466e-02, -6.2684e-02]],\n",
      "\n",
      "         [[ 6.0286e-03, -8.6017e-02,  1.8790e-03,  ...,  9.4438e-02,\n",
      "           -1.1565e-01, -2.8499e-02],\n",
      "          [ 7.4545e-02,  7.0307e-02, -6.1361e-02,  ...,  7.4847e-03,\n",
      "            2.2679e-02, -9.0843e-02],\n",
      "          [-1.0983e-02, -2.9161e-02,  2.6927e-02,  ..., -4.8374e-02,\n",
      "           -2.6786e-03,  1.3675e-02],\n",
      "          ...,\n",
      "          [ 9.8016e-03, -1.8348e-01, -9.1638e-02,  ..., -6.6249e-02,\n",
      "            3.6957e-02, -1.0155e-01],\n",
      "          [-8.1644e-02,  2.9288e-02, -8.2891e-03,  ..., -7.8859e-02,\n",
      "            6.1772e-03,  2.0028e-02],\n",
      "          [-2.2178e-02, -2.1392e-02,  1.0176e-01,  ...,  7.4295e-02,\n",
      "           -5.0119e-02, -3.3395e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 6.7165e-02, -2.7103e-02, -3.4633e-02,  ...,  3.7338e-02,\n",
      "            3.8121e-02,  1.5164e-02],\n",
      "          [-1.0884e-01,  2.0483e-02,  1.0340e-02,  ...,  1.0658e-02,\n",
      "           -1.4513e-02,  3.6700e-02],\n",
      "          [ 2.0057e-02, -6.6675e-02,  9.5041e-02,  ...,  1.2942e-02,\n",
      "           -2.2458e-02,  3.0502e-02],\n",
      "          ...,\n",
      "          [-2.2576e-02, -5.1181e-02,  1.4606e-03,  ..., -4.4678e-02,\n",
      "            9.3206e-03, -2.2677e-02],\n",
      "          [ 6.1245e-03, -3.7944e-02, -4.5019e-02,  ...,  3.8972e-02,\n",
      "           -3.1325e-02,  2.0290e-02],\n",
      "          [-9.4159e-03, -2.4764e-02,  1.3595e-02,  ..., -8.4818e-03,\n",
      "           -2.3752e-03,  1.7789e-02]],\n",
      "\n",
      "         [[ 6.0850e-03,  1.7208e-02,  3.6729e-02,  ...,  5.5213e-02,\n",
      "           -2.5003e-02, -6.3940e-02],\n",
      "          [ 9.2255e-03, -3.5808e-02,  2.2412e-03,  ...,  2.0793e-03,\n",
      "            8.7824e-02,  3.8410e-02],\n",
      "          [ 4.4712e-02,  6.6017e-03,  3.7666e-02,  ..., -9.0011e-02,\n",
      "           -4.6181e-02, -1.6399e-03],\n",
      "          ...,\n",
      "          [-4.1333e-02,  2.1526e-02,  2.0400e-02,  ...,  2.2573e-02,\n",
      "           -2.2483e-02,  1.7130e-02],\n",
      "          [-4.7272e-02, -3.6024e-02,  7.5365e-03,  ..., -2.7192e-02,\n",
      "           -3.2157e-02, -1.3998e-02],\n",
      "          [ 3.7908e-02,  6.9966e-03, -1.7692e-02,  ...,  8.6096e-02,\n",
      "            4.8063e-02, -4.0371e-02]],\n",
      "\n",
      "         [[-3.6107e-02, -7.2876e-02, -1.0396e-02,  ...,  9.7284e-03,\n",
      "           -8.5593e-02, -4.4522e-02],\n",
      "          [ 8.4271e-02, -4.8944e-02, -5.9304e-02,  ..., -3.8863e-02,\n",
      "            2.9712e-02, -1.0382e-02],\n",
      "          [ 1.3384e-02, -2.6647e-02, -6.1870e-03,  ..., -3.5142e-02,\n",
      "           -5.8294e-02, -6.6316e-03],\n",
      "          ...,\n",
      "          [ 1.5215e-02, -7.2955e-02, -3.5179e-02,  ..., -6.7826e-02,\n",
      "            2.7353e-03, -1.5412e-02],\n",
      "          [-7.0212e-02,  3.0277e-02, -7.4741e-02,  ...,  2.0349e-02,\n",
      "           -1.4392e-02, -5.8539e-02],\n",
      "          [-2.0754e-02,  3.2886e-02,  8.0489e-02,  ...,  2.7357e-02,\n",
      "            7.3470e-03, -9.7798e-02]]]], device='cuda:0',\n",
      "       grad_fn=<ViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "generator, _, _ , _ = load_model(config, 0)\n",
    "generator.eval()\n",
    "\n",
    "z = torch.randn(config.batch_size, config.in_dim).to(device)\n",
    "images = generator(z).view(-1, *shape)\n",
    "\n",
    "print(images)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('3.9.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3b5149f69c5c71e17d563646443db8801bb1e0a6ffc5a9144cdfc320ca09ead"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
