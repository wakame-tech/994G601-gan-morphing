{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "writer = SummaryWriter(f'runs/mnist_gan_exp_{timestamp}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(0.5, 0.5)\n",
    "])\n",
    "# data = datasets.MNIST(root='./dataset', download=True, transform=transform)\n",
    "# <https://stackoverflow.com/questions/70896841/error-downloading-celeba-dataset-using-torchvision>\n",
    "data = datasets.CelebA(root='./dataset', download=True, transform=transform)\n",
    "size = 10000\n",
    "data, _ = random_split(data, [size, len(data) - size])\n",
    "batch_size: int = 256\n",
    "dataloader = DataLoader(data, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "n_epochs = 10\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, in_dim: int, out_dim: int):\n",
    "        super(Generator, self).__init__()\n",
    "        sizes = [in_dim, 256, 512, 1024, out_dim]\n",
    "        self.fc1 = nn.Linear(sizes[0], sizes[1])\n",
    "        self.fc2 = nn.Linear(sizes[1], sizes[2])\n",
    "        self.fc3 = nn.Linear(sizes[2], sizes[3])\n",
    "        self.fc4 = nn.Linear(sizes[3], sizes[4])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        slope = 0.2\n",
    "        x = F.leaky_relu(self.fc1(x), slope)\n",
    "        x = F.leaky_relu(self.fc2(x), slope)\n",
    "        x = F.leaky_relu(self.fc3(x), slope)\n",
    "        x = F.tanh(self.fc4(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_dim: int):\n",
    "        super(Discriminator, self).__init__()\n",
    "        sizes = [in_dim, 1024, 512, 256, 1]\n",
    "        self.fc1 = nn.Linear(sizes[0], sizes[1])\n",
    "        self.fc2 = nn.Linear(sizes[1], sizes[2])\n",
    "        self.fc3 = nn.Linear(sizes[2], sizes[3])\n",
    "        self.fc4 = nn.Linear(sizes[3], sizes[4])\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # leaky relu slope\n",
    "        slope = 0.2\n",
    "        # dropout rate\n",
    "        dropout = 0.3\n",
    "        x = F.leaky_relu(self.fc1(x), slope)\n",
    "        x = F.dropout(x, dropout)\n",
    "        x = F.leaky_relu(self.fc2(x), slope)\n",
    "        x = F.dropout(x, dropout)\n",
    "        x = F.leaky_relu(self.fc3(x), slope)\n",
    "        x = F.dropout(x, dropout)\n",
    "        x = F.sigmoid(self.fc4(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2022-06-11 21:17:28.010473] Epoch 0\n",
      "[2022-06-11 21:17:28.349190] Epoch 0 batch 0\n",
      "[2022-06-11 21:17:28.978848] Epoch 0 batch 1\n",
      "[2022-06-11 21:17:29.594143] Epoch 0 batch 2\n",
      "[2022-06-11 21:17:35.513948] Epoch 1\n",
      "[2022-06-11 21:17:37.076653] Epoch 1 batch 0\n",
      "[2022-06-11 21:17:37.691240] Epoch 1 batch 1\n",
      "[2022-06-11 21:17:38.296946] Epoch 1 batch 2\n",
      "[2022-06-11 21:17:44.813323] Epoch 2\n",
      "[2022-06-11 21:17:46.692300] Epoch 2 batch 0\n",
      "[2022-06-11 21:17:47.553536] Epoch 2 batch 1\n",
      "[2022-06-11 21:17:48.459173] Epoch 2 batch 2\n",
      "[2022-06-11 21:17:54.814449] Epoch 3\n",
      "[2022-06-11 21:17:56.822811] Epoch 3 batch 0\n",
      "[2022-06-11 21:17:57.438916] Epoch 3 batch 1\n",
      "[2022-06-11 21:17:58.041238] Epoch 3 batch 2\n",
      "[2022-06-11 21:18:04.398869] Epoch 4\n",
      "[2022-06-11 21:18:06.518738] Epoch 4 batch 0\n",
      "[2022-06-11 21:18:07.343023] Epoch 4 batch 1\n",
      "[2022-06-11 21:18:08.121174] Epoch 4 batch 2\n",
      "[2022-06-11 21:18:14.445384] Epoch 5\n",
      "[2022-06-11 21:18:16.045917] Epoch 5 batch 0\n",
      "[2022-06-11 21:18:16.709247] Epoch 5 batch 1\n",
      "[2022-06-11 21:18:17.415242] Epoch 5 batch 2\n",
      "[2022-06-11 21:18:23.539272] Epoch 6\n",
      "[2022-06-11 21:18:24.835346] Epoch 6 batch 0\n",
      "[2022-06-11 21:18:25.425086] Epoch 6 batch 1\n",
      "[2022-06-11 21:18:26.026934] Epoch 6 batch 2\n",
      "[2022-06-11 21:18:31.951888] Epoch 7\n",
      "[2022-06-11 21:18:33.702107] Epoch 7 batch 0\n",
      "[2022-06-11 21:18:34.633763] Epoch 7 batch 1\n",
      "[2022-06-11 21:18:35.303113] Epoch 7 batch 2\n",
      "[2022-06-11 21:18:41.196817] Epoch 8\n",
      "[2022-06-11 21:18:43.351939] Epoch 8 batch 0\n",
      "[2022-06-11 21:18:43.972196] Epoch 8 batch 1\n",
      "[2022-06-11 21:18:44.724832] Epoch 8 batch 2\n",
      "[2022-06-11 21:18:50.607848] Epoch 9\n",
      "[2022-06-11 21:18:53.102852] Epoch 9 batch 0\n",
      "[2022-06-11 21:18:53.750787] Epoch 9 batch 1\n",
      "[2022-06-11 21:18:54.450071] Epoch 9 batch 2\n"
     ]
    }
   ],
   "source": [
    "def train_discriminator(\n",
    "    generator: Generator, \n",
    "    discriminator: Discriminator, \n",
    "    optim_discriminator, \n",
    "    x: torch.Tensor,\n",
    "    criterion,\n",
    "    batch_size: int,\n",
    "    step: int,\n",
    "):\n",
    "    discriminator.zero_grad()\n",
    "    x_real, y_real = x.view(-1, out_dim).to(device), torch.ones(batch_size, 1).to(device)\n",
    "    x_real, y_real = Variable(x_real), Variable(y_real)\n",
    "    \n",
    "    d_output = discriminator(x_real)\n",
    "    # print(f'd_output: {d_output.shape}, y_real: {y_real.shape}')\n",
    "    loss_real = criterion(d_output, y_real)\n",
    "\n",
    "    # train discriminator with fake data\n",
    "    z = Variable(torch.randn(batch_size, in_dim, device = device))\n",
    "    x_fake, y_fake = generator(z), torch.zeros(batch_size, 1).to(device)\n",
    "    \n",
    "    d_output = discriminator(x_fake)\n",
    "    loss_fake = criterion(d_output, y_fake)\n",
    "\n",
    "    loss = loss_real + loss_fake\n",
    "    loss.backward()\n",
    "    optim_discriminator.step()\n",
    "    l = loss.item()\n",
    "    del loss\n",
    "    writer.add_scalar('loss/discriminator', l, step)\n",
    "    \n",
    "def train_generator(\n",
    "    generator: Generator,\n",
    "    discriminator: Discriminator,\n",
    "    optim_generator,\n",
    "    criterion,\n",
    "    batch_size,\n",
    "    step: int,\n",
    "):\n",
    "    generator.zero_grad()\n",
    "    z = Variable(torch.randn(batch_size, in_dim, device = device))\n",
    "    y = Variable(torch.ones(batch_size, 1).to(device))\n",
    "\n",
    "    g_output = generator(z)\n",
    "    d_output = discriminator(g_output)\n",
    "    loss_generator = criterion(d_output, y)\n",
    "\n",
    "    loss_generator.backward()\n",
    "    optim_generator.step()\n",
    "    loss = loss_generator.item()\n",
    "    writer.add_scalar('loss/generator', loss, step)\n",
    "    del loss_generator\n",
    "\n",
    "\n",
    "def train(\n",
    "    writer: SummaryWriter,\n",
    "    generator: Generator, \n",
    "    discriminator: Discriminator, \n",
    "    dataloader: DataLoader, \n",
    "    n_epochs: int, \n",
    "):\n",
    "    criterion = nn.BCELoss()\n",
    "    lr = 0.0001\n",
    "    optim_generator = optim.AdamW(generator.parameters(), lr=lr)\n",
    "    optim_discriminator = optim.Adam(discriminator.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        print(f'[{datetime.datetime.now()}] Epoch {epoch}')\n",
    "        for i, (x, _) in enumerate(dataloader):\n",
    "            x = x.to(device)\n",
    "            print(f'[{datetime.datetime.now()}] Epoch {epoch} batch {i}')\n",
    "            step = epoch * len(dataloader) + i\n",
    "            train_discriminator(generator, discriminator, optim_discriminator, x, criterion, batch_size, step)\n",
    "            train_generator(generator, discriminator, optim_generator, criterion, batch_size, step)\n",
    "\n",
    "        # generate image\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(batch_size, in_dim).to(device)\n",
    "            images = generator(z).view(-1, *shape)\n",
    "            writer.add_images(f'generated_image', images, epoch)\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "            torch.save(generator.state_dict(), f'models/generator.pt')\n",
    "            torch.save(discriminator.state_dict(), f'models/discriminator.pt')\n",
    "\n",
    "# (channel, width, height)\n",
    "shape = iter(dataloader).next()[0].shape[1:]\n",
    "print(f'Shape: {shape}')\n",
    "in_dim = 100\n",
    "out_dim = shape[0] * shape[1] * shape[2]\n",
    "generator = Generator(in_dim, out_dim).to(device)\n",
    "discriminator = Discriminator(out_dim).to(device)\n",
    "train(writer, generator, discriminator, dataloader, n_epochs = n_epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('3.9.6')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a3b5149f69c5c71e17d563646443db8801bb1e0a6ffc5a9144cdfc320ca09ead"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
